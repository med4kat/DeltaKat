
<!doctype html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>DeltaKat</title>

  <meta name="author" content="Kat">
  <meta name="keywords" content="Python, AI, options, Delta">
  <meta name="robots" content="index, follow">

  <meta name="description" content="Where Python meets profit (or not): coding, AI, options and flying by Delta.">
  <link rel="icon" href="./cat-solid.svg" type="image/x-icon">
  <link rel="apple-touch-icon" href="./cat-solid.svg">

  
  <link rel="stylesheet" href="https://unpkg.com/@highlightjs/cdn-assets@11.11.1/styles/default.min.css">
<script src="https://unpkg.com/@highlightjs/cdn-assets@11.11.1/highlight.min.js"></script>

<!-- and it's easy to individually load additional languages -->
<script src="https://unpkg.com/@highlightjs/cdn-assets@11.11.1/languages/python.min.js"></script>
<script src="https://unpkg.com/@highlightjs/cdn-assets@11.11.1/languages/json.min.js"></script>
<script>hljs.highlightAll();</script>

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link
    href="https://fonts.googleapis.com/css2?family=Inter:ital,opsz,wght@0,14..32,100..900;1,14..32,100..900&display=swap"
    rel="stylesheet">

  <link rel="stylesheet" href="style.css">
</head>

<body>
  <main style="display:flex; align-items: center; flex-direction: column;">
   <section style="display: flex; flex-direction: column; gap: 0.2rem;">
<h1>Bigrams and Disappointment:</h1>
<h2>A Very Short AI Adventure</h2>
<p>2025-04-20 </p>
<p><img alt="alt text" src="Bigrams.png" /></p>
<h2>1. Setup: Curiosity Begins</h2>
<p>I got really excited about all this AI stuff. Everyone kept saying, "It's just predicting the next word." Cool. But <em>why</em> does that work?</p>
<p>So I started from the beginning: <strong>Statistical Language Models</strong>, specifically <strong>bigrams</strong>. Predict the next word based on the last. Like T9, but with hope.</p>
<p>By the way, according to <a href="https://www.youtube.com/watch?v=rCtvAvZtJyE">Dr. Lisa Feldman Barrett</a>, the human brain works a bit like T9 too. What a funny coincidence!</p>
<hr />
<h2>2. The Plan</h2>
<p>Let’s keep it simple:</p>
<ul>
<li>Use <strong>NewsAPI</strong> to get recent semiconductor headlines</li>
<li>Tokenise them using <strong>NLTK</strong></li>
<li>Count the most frequent bigrams</li>
</ul>
<p>Result? Total nonsense.</p>
<pre><code class="language-json">[  
    [[&quot;smart&quot;, &quot;glasses&quot;], 4],
    [[&quot;lowest&quot;, &quot;price&quot;], 3],
    [[&quot;motorola&quot;, &quot;razr&quot;], 3],
    [[&quot;samsung&quot;, &quot;galaxy&quot;], 3],
    [[&quot;la&quot;, &quot;gama&quot;], 3]
]
</code></pre>
<p>Some of these make sense. Most don’t. “la gama”? Really?</p>
<p><img alt="alt text" src="bigram_word_cloud.png" /></p>
<hr />
<h2>3. I Refuse to Give Up</h2>
<p>Next up: <strong>sentiment analysis</strong> with <code>TextBlob</code>.</p>
<p>It gives you:</p>
<ul>
<li><strong>Polarity</strong>: is it positive or negative?</li>
<li><strong>Subjectivity</strong>: is it fact or opinion?</li>
</ul>
<p>Here’s an actual result from one of the news headlines:</p>
<pre><code class="language-json">{&quot;headline&quot;: &quot;Cerebras CEO actually finds common ground with Nvidia as startup notches IBM win&quot;, 
&quot;polarity&quot;: 0.17, 
&quot;subjectivity&quot;: 0.33}
</code></pre>
<p>Which kinda reads like: “meh, slightly positive, not too opinionated.”
  …and to be fair, that’s not wrong. But is it useful?</p>
<p>Not really. Most headlines just came back as zeros—no strong emotions, no real opinions. A lot of them were either too dry or too clickbaity for the sentiment tool to pick up anything useful.</p>
<hr />
<h2>4. A Final Push: Stock Data</h2>
<p>Alright, let’s <em>really</em> try:</p>
<ul>
<li>Pull daily stock prices from <code>yfinance</code></li>
<li>Match those to daily average sentiment</li>
<li>Look for correlation</li>
</ul>
<p>Polarity vs. price change? Nothing. Volume vs. subjectivity? Nope.</p>
<p><img width="400"alt="alt text" src="corr_matrix.png" /></p>
<hr />
<h2>5. What I Learned</h2>
<p>So yeah—it didn’t work. At all.</p>
<p>But here’s what I took away:</p>
<ul>
<li><strong>Bigram models</strong> are too shallow for modern news</li>
<li><strong>TextBlob sentiment</strong> struggles with finance headlines</li>
<li><strong>News-to-market correlation</strong> is messy, subtle, or nonexistent</li>
</ul>
<p>That doesn’t mean the effort was wasted. It means I now understand <em>why</em> bigrams got left behind.</p>
<p>Like dial-up. Important, but not something you’d want to use today.</p>
<hr />
<h2>6. What’s Next</h2>
<p>Stage II: <strong>Neural Language Models (2000s)</strong> Before ChatGPT, there were RNNs and early LSTM models.</p>
<p>Can I do anything interesting with them? Let’s find out.</p>
<hr />
<h2>Repo: <a href="https://github.com/med4kat/bigram-news-experiment">GitHub - bigram-news-experiment</a></h2>
<p>Includes:</p>
<ul>
<li>Scripts for collecting and analysing news headlines</li>
<li>Sentiment results</li>
<li>Stock data correlation attempts</li>
<li>Everything that didn’t work</li>
</ul>
<hr />
    </section>
    </main>
    <footer style="height: 1.5rem; display: flex; justify-content: center; margin-top: 1.5rem;">
      <a href="https://www.linkedin.com/in/katrina-medvedeva-7a849012/" target="_blank"><img src="LI-In-Bug.png"
          alt="Katrina's Linkedin Profile" style="height: 100%"></a>
      <a href="https://github.com/med4kat" target="_blank"><img src="GitHub-Mark-120px-plus.png"
          alt="Katrina's GitHub Profile" style="height: 100%"></a>
    </footer>

</body>

</html>

